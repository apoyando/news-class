{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Using NMF on sparse data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:\n",
    "I will load the movie ratings sample data from the MovieLens dataset and use sklearn matrix factorization to predict the missing ratings from the test data and measure the RMSE.\n",
    "\n",
    "To account for missing data, I am imputing all of a user's unrated movies to a 3. For the number of latent factors, I will use the number of genre columns in the movies table (18)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "MV_users = pd.read_csv('movie-data/users.csv')\n",
    "MV_movies = pd.read_csv('movie-data/movies.csv')\n",
    "train = pd.read_csv('movie-data/train.csv')\n",
    "test = pd.read_csv('movie-data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF RMSE with imputed threes on test set: 1.1062\n"
     ]
    }
   ],
   "source": [
    "num_users = MV_users['uID'].max()\n",
    "num_movies = MV_movies['mID'].max()\n",
    "\n",
    "# Create a full user-movie matrix of threes\n",
    "user_movie_matrix_train = np.full((num_users, num_movies), 3.0)\n",
    "\n",
    "# Populate the matrix with ratings from the training data\n",
    "for _, row in train.iterrows():\n",
    "    # Adjust for 0-based indexing if IDs start from 1\n",
    "    user_idx = row['uID'] - 1\n",
    "    movie_idx = row['mID'] - 1\n",
    "    rating = row['rating']\n",
    "    if user_idx < num_users and movie_idx < num_movies:\n",
    "        user_movie_matrix_train[user_idx, movie_idx] = rating\n",
    "\n",
    "# Create a sparse matrix for NMF for efficiency\n",
    "user_movie_sparse_train = csr_matrix(user_movie_matrix_train)\n",
    "\n",
    "# For the number of latent factors, I am using the number of genre columns in the movies table.\n",
    "n_components = 18\n",
    "\n",
    "# Initialize and fit the NMF model on the training data matrix\n",
    "nmf_model = NMF(n_components=n_components, init='nndsvda', max_iter=1000, random_state=42)\n",
    "user_factors = nmf_model.fit_transform(user_movie_sparse_train)\n",
    "movie_factors = nmf_model.components_\n",
    "\n",
    "# Reconstruct the matrix to predict missing ratings for the entire matrix\n",
    "predicted_ratings_full_matrix = np.dot(user_factors, movie_factors)\n",
    "\n",
    "# Predict ratings for the test data\n",
    "test_predictions = []\n",
    "for _, row in test.iterrows():\n",
    "    # Adjust for 0-based indexing\n",
    "    user_idx = row['uID'] - 1\n",
    "    movie_idx = row['mID'] - 1\n",
    "    predicted_rating = predicted_ratings_full_matrix[user_idx, movie_idx]\n",
    "    test_predictions.append(predicted_rating)\n",
    "\n",
    "# Calculate RMSE on the test data\n",
    "test_true_ratings = test['rating'].values\n",
    "rmse = sqrt(mean_squared_error(test_true_ratings, test_predictions))\n",
    "\n",
    "print(f\"NMF RMSE with imputed threes on test set: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model took an excruciatingly long time to run and had a RMSE worse than all my collaborative models for this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "Now I will discuss the results and why sklearn's non-negative matrix facorization library did not work well compared to the simple baseline or similarity-based methods I did in an earlier model, and suggest a way(s) to fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why sklearn.decomposition.NMF performs poorly with this data\n",
    "Naive Handling of Missing Data: As explained previously, sklearn's NMF requires a complete matrix. By filling missing values with 0s, we introduce a strong bias. The model learns that a non-rated item is equivalent to a poorly rated one, which is inaccurate. This fundamentally misrepresents the data, leading to poor predictions for true missing ratings.\n",
    "No Bias Terms: The standard NMF implementation lacks user and item bias terms. In collaborative filtering, these biases are crucial for accurately modeling user behavior. For example, a user who is generally stingy with ratings (low user bias) and a movie that is universally loved (high item bias) are important factors that the simple NMF model ignores.\n",
    "Non-negativity Constraint: NMF's constraint of non-negative matrices can be too restrictive for modeling user preferences, which may have both positive and negative components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why other methods might work better\n",
    "Simple Baseline: A baseline approach could involve predicting the average rating for a user, or a movie, or the global average. These simple methods often perform better because they capture important biases that the naive NMF model ignores.\n",
    "Similarity-Based Methods: Collaborative filtering models that use similarity (e.g., user-user or item-item) directly handle the sparsity of the data and are not susceptible to the imputation problem. \n",
    "Suggested ways to fix and improve\n",
    "Use a Dedicated Library (surprise): The surprise library is built for recommender systems and includes an NMF implementation that correctly handles missing data. It avoids the need for imputation and includes bias terms, which would significantly improve performance.\n",
    "Custom Implementation with Stochastic Gradient Descent (SGD): If constrained to sklearn's components, a custom SGD approach could be implemented. This would involve:\n",
    "Iterating only over the known ratings in the training data.\n",
    "Adding and updating user and item bias terms during each iteration.\n",
    "Updating user and item latent factor matrices based on the gradients of the known ratings.\n",
    "Use a sklearn Alternative that handles sparsity: The sklearn.decomposition.TruncatedSVD can operate on sparse matrices directly. While not NMF, it is another form of matrix factorization that could provide better performance with sparse data.\n",
    "Advanced Imputation: A better imputation strategy could be to fill missing ratings with the user's average rating or the movie's average rating, rather than just 0. While still not ideal, it's a step up from a simple zero-filled approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
